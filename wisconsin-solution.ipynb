{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer - Wisconsin \n",
    "\n",
    "TODO: add banner image from wisconsin kaggle dataset\n",
    "\n",
    "TODO: add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to dataset\n",
    "path = \"./datasets/data.csv\"\n",
    "original_df = pd.read_csv(path)\n",
    "\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of our dataset\n",
    "original_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type summary of our dataset\n",
    "original_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect null values, lucky that we don't have any\n",
    "original_df.isnan.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1. Seperate target and dataset\n",
    "target_df = original_df['diagnosis']\n",
    "data_df = original_df.drop(columns=['diagnosis'])\n",
    "\n",
    "print(\"Shape of target df: \", target_df.shape)\n",
    "print(\"Shape of dataset: \", data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2. Change target to binary representation\n",
    "target_df = target_df.replace({ 'Benign':0, 'Malignant': 1}).astype('int')\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3. Normalize input data of floating point\n",
    "columns = data_df.columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "scl_np = std_scaler.fit_transform(data_df.values) #fit the numpy rep of df\n",
    "data_df = pd.DataFrame(scl_np)\n",
    "\n",
    "#put columns label back\n",
    "data_df.columns = columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature selection by exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as we remember from wisconsin-visualization, we plan to drop the following features:\n",
    "* For Feature Selection using Exploratory Analysis from Data Viz:\n",
    "    - Drop columns: compactness_se, concavity_se, concave points_se\n",
    "    - Drop columns: texture_se, perimeter_se\n",
    "    - Drop columns: radius_worst, texture_worst, perimeter_worst\n",
    "    - Drop columns: compactness_worst, concavity_worst, concave point_worst\n",
    "    - Drop columns: perimeter_mean and area_mean\n",
    "    - Drop columns: smoothness_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Drop any weak or redundant features\n",
    "dropped_feats = [\"compactness_se\",  \"concavity_se\", \"concave points_se\", \n",
    "                \"texture_se\", \"perimeter_se\", \"radius_worst\", \"texture_worst\", \"perimeter_worst\",\n",
    "                \"compactness_worst\", \"concavity_worst\", \"concave point_worst\",\n",
    "                \"perimeter_mean\", \"area_mean\", \"smoothness_se\"]\n",
    "print(\"Number of features dropped: \", len(dropped_feats))\n",
    "\n",
    "#dropping\n",
    "data_cleaned_df = data_df.drop(dropped_feats, axis=1)\n",
    "\n",
    "print(\"Shape of dataset after dropping weak features: \", data_cleaned_df.shape)\n",
    "data_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 train split test\n",
    "\n",
    "#make sure both target and dataset df has same index\n",
    "print(\"Index of target df: \", target_df.index)\n",
    "print(\"Index of dataset df: \", data_cleaned_df.index)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_cleaned_df, target_df, test_size=0.23, random_state=42)\n",
    "\n",
    "#make sure size of each train-test splits\n",
    "print(\"Size of trained X-y: \", X_train, y_train)\n",
    "print(\"Size of test X-y: \", X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 define get_accuracy__rocauc function\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "def get_acc_rocauc(X_train_test, y_train_test, max_depth=7, n_trees=100):\n",
    "    X_train, X_test = X_train_test\n",
    "    y_train, y_test = y_train_test\n",
    "    #define RandomForest model\n",
    "    rforest_clf = RandomForestClassifier(n_estimators=n_trees, max_depth=max_depth,\n",
    "                                        random_state=42, n_jobs=-1)\n",
    "    rforest_clf.fit(X_train, y_train)\n",
    "    #accuracy score\n",
    "    y_pred = rforest_clf.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    #prediction probability \n",
    "    pred_proba = rforest_clf.predict_proba(X_test)[:,1]\n",
    "    auc_score = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    return acc_score, auc_score, pred_proba, y_pred\n",
    "\n",
    "# 1.4 define roc curve plotting function\n",
    "def plot_roc_curve(pred_proba, y_test):\n",
    "    #calculating\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #plotting\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label=\"ROC Curve Area=%.2f\" %roc_auc)\n",
    "    plt.plot([0,1], [0,1], color='Navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic\")\n",
    "    plt.show()\n",
    "\n",
    "# 1.5 define confusion matrix calculation function\n",
    "def get_plt_conf_mat(acc_score, y_test):\n",
    "    conf_mat = confussion_matrix(y_test, acc_score)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Univariate Feature Selection using chi quare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 split training and test data\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "k_list = [5, 10, 14, 15, 16]\n",
    "\n",
    "# 2.1 define feature selecting function for any given k\n",
    "def select_K_features(X_train, y_train, k):\n",
    "    feature_selector = SelectKBest(chi2, k=k).fit(X_train, y_train)\n",
    "    feats_imp = feature_selector.scores_\n",
    "    feats_argsort = np.argsort(feats_imp)[::-1] #from higher importance to lower\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
